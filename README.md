# ğŸ§  Wikipedia Q&A Assistant

A dynamic chatbot that retrieves Wikipedia articles on-the-fly, indexes them into Pinecone using HuggingFace embeddings, and answers your questions using Groq's LLaMA3-70B model. Built with LangChain and fully memory-aware.

---

## ğŸš€ Features

- ğŸ” **Dynamic Retrieval**: Fetches and indexes Wikipedia articles based on your first query.
- ğŸ§© **Chunking + Embedding**: Splits text and embeds it using `all-MiniLM-L6-v2`.
- ğŸ“¦ **Vector Search**: Stores and searches context chunks in Pinecone.
- ğŸ’¬ **Conversational Memory**: Remembers past interactions using LangChain's memory.
- ğŸ¤– **Groq LLM**: Powered by ultra-fast `llama3-70b-8192` via Groq API.
- ğŸ’¡ **Custom RAG Prompt**: Manually crafted prompt template for accurate, grounded answers.

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ main.py               # Main chatbot script
â”œâ”€â”€ .env                  # Stores API keys securely
â”œâ”€â”€ requirements.txt      # All dependencies
â””â”€â”€ README.md             # This file
